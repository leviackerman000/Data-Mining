{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgVXYKsxAQ1S"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbHS6fHRkGqR",
        "outputId": "8dbab38f-9f3b-41d1-8120-3886a48c082a"
      },
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "print('Fashion MNIST Dataset Shape:')\n",
        "print('X_train: ' + str(X_train.shape))\n",
        "print('Y_train: ' + str(Y_train.shape))\n",
        "print('X_test:  '  + str(X_test.shape))\n",
        "print('Y_test:  '  + str(Y_test.shape))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Fashion MNIST Dataset Shape:\n",
            "X_train: (60000, 28, 28)\n",
            "Y_train: (60000,)\n",
            "X_test:  (10000, 28, 28)\n",
            "Y_test:  (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "RX3xAj1JpJMG",
        "outputId": "5e77fc5f-0d25-4d13-d799-3a9789a70768"
      },
      "source": [
        "X_train[1]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,  41, 188, 103,\n",
              "         54,  48,  43,  87, 168, 133,  16,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   1,   0,   0,   0,  49, 136, 219, 216, 228, 236,\n",
              "        255, 255, 255, 255, 217, 215, 254, 231, 160,  45,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  14, 176, 222, 224, 212, 203, 198, 196,\n",
              "        200, 215, 204, 202, 201, 201, 201, 209, 218, 224, 164,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 188, 219, 200, 198, 202, 198, 199, 199,\n",
              "        201, 196, 198, 198, 200, 200, 200, 200, 201, 200, 225,  41,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  51, 219, 199, 203, 203, 212, 238, 248, 250,\n",
              "        245, 249, 246, 247, 252, 248, 235, 207, 203, 203, 222, 140,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 116, 226, 206, 204, 207, 204, 101,  75,  47,\n",
              "         73,  48,  50,  45,  51,  63, 113, 222, 202, 206, 220, 224,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 200, 222, 209, 203, 215, 200,   0,  70,  98,\n",
              "          0, 103,  59,  68,  71,  49,   0, 219, 206, 214, 210, 250,  38,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 247, 218, 212, 210, 215, 214,   0, 254, 243,\n",
              "        139, 255, 174, 251, 255, 205,   0, 215, 217, 214, 208, 220,  95,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,  45, 226, 214, 214, 215, 224, 205,   0,  42,  35,\n",
              "         60,  16,  17,  12,  13,  70,   0, 189, 216, 212, 206, 212, 156,\n",
              "          0,   0],\n",
              "       [  0,   0,   0, 164, 235, 214, 211, 220, 216, 201,  52,  71,  89,\n",
              "         94,  83,  78,  70,  76,  92,  87, 206, 207, 222, 213, 219, 208,\n",
              "          0,   0],\n",
              "       [  0,   0,   0, 106, 187, 223, 237, 248, 211, 198, 252, 250, 248,\n",
              "        245, 248, 252, 253, 250, 252, 239, 201, 212, 225, 215, 193, 113,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  17,  54, 159, 222, 193, 208, 192, 197,\n",
              "        200, 200, 200, 200, 201, 203, 195, 210, 165,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  47, 225, 192, 214, 203, 206,\n",
              "        204, 204, 205, 206, 204, 212, 197, 218, 107,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   1,   6,   0,  46, 212, 195, 212, 202, 206,\n",
              "        205, 204, 205, 206, 204, 212, 200, 218,  91,   0,   3,   1,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,  11, 197, 199, 205, 202, 205,\n",
              "        206, 204, 205, 207, 204, 205, 205, 218,  77,   0,   5,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   3,   0,   2, 191, 198, 201, 205, 206,\n",
              "        205, 205, 206, 209, 206, 199, 209, 219,  74,   0,   5,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   2,   0,   0, 188, 197, 200, 207, 207,\n",
              "        204, 207, 207, 210, 208, 198, 207, 221,  72,   0,   4,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   2,   0,   0, 215, 198, 203, 206, 208,\n",
              "        205, 207, 207, 210, 208, 200, 202, 222,  75,   0,   4,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 212, 198, 209, 206, 209,\n",
              "        206, 208, 207, 211, 206, 205, 198, 221,  80,   0,   3,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 204, 201, 205, 208, 207,\n",
              "        205, 211, 205, 210, 210, 209, 195, 221,  96,   0,   3,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 202, 201, 205, 209, 207,\n",
              "        205, 213, 206, 210, 209, 210, 194, 217, 105,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 204, 204, 205, 208, 207,\n",
              "        205, 215, 207, 210, 208, 211, 193, 213, 115,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 204, 207, 207, 208, 206,\n",
              "        206, 215, 210, 210, 207, 212, 195, 210, 118,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 198, 208, 208, 208, 204,\n",
              "        207, 212, 212, 210, 207, 211, 196, 207, 121,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 198, 210, 207, 208, 206,\n",
              "        209, 213, 212, 211, 207, 210, 197, 207, 124,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 172, 210, 203, 201, 199,\n",
              "        204, 207, 205, 204, 201, 205, 197, 206, 127,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 188, 221, 214, 234, 236,\n",
              "        238, 244, 244, 244, 240, 243, 214, 224, 162,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 139, 146, 130, 135, 135,\n",
              "        137, 125, 124, 125, 121, 119, 114, 130,  76,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-9db71b67-bc4a-4635-9570-4cebb25bf730\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB90lEQVR4nF2QvWvTURSGn3PuTUwaSVMtlLZDBT+g0CragnQQwcnFQRAcdHNy0KngXyAIDg5O4qKuDrrp4ChFOthBsNrSxZZ0MMXYD5tffvfe45CkX2d9eF7e9wgAYsD487cL7Xzi5srTJvsnwMUnyz/WGmZmPxfT+qvJPQDVN+d1ezdPvn8nGZTKxc939+CnsY3kg6C5ooDY8PVF8ABTYw3vyiN9mvsohbC1Foj3Zrvm7MNGcvFFfW1kXfPi8UsPGr7qT4EC3ArOSuFlPvXhcnlocPNZ9KV/I+e6sRdW3TGqfNwZn313w3+dCpWYfs0s4YHJ30FdeYOJbPix5DJDfTSl1pXXeOBReTuWW2H65InCUN4q1m4P7PZLcboTOzd0plpZjl9Sis5L1K2litP6+97OgbP3r672NwsOEG31f7sDdAvxZz67ZsWKS4ikUrs01/mrAkgR23LJujmOJk560HJW/voMExCyApuo9SDKbtuCExNRbXuJB2IxUjRTMRVRS5qwfQiMijMRAM3FHTaJFBERJBWCFY6YLRc0mUvmfaR20AQSCKhgYqHcMX0PKlgHqoU+DnzIAAcmOEw0Hiok0BYhSVQwie5IIdRQFaTjH55SJ2RZ3s6ydo65I4VqFT+oWoTgVvtOo2kPirHwvVlAt01CymvzJID/CjnVF438ZwEAAAAASUVORK5CYII=\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,  41, 188, 103,\n",
              "         54,  48,  43,  87, 168, 133,  16,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   1,   0,   0,   0,  49, 136, 219, 216, 228, 236,\n",
              "        255, 255, 255, 255, 217, 215, 254, 231, 160,  45,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  14, 176, 222, 224, 212, 203, 198, 196,\n",
              "        200, 215, 204, 202, 201, 201, 201, 209, 218, 224, 164,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 188, 219, 200, 198, 202, 198, 199, 199,\n",
              "        201, 196, 198, 198, 200, 200, 200, 200, 201, 200, 225,  41,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  51, 219, 199, 203, 203, 212, 238, 248, 250,\n",
              "        245, 249, 246, 247, 252, 248, 235, 207, 203, 203, 222, 140,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 116, 226, 206, 204, 207, 204, 101,  75,  47,\n",
              "         73,  48,  50,  45,  51,  63, 113, 222, 202, 206, 220, 224,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 200, 222, 209, 203, 215, 200,   0,  70,  98,\n",
              "          0, 103,  59,  68,  71,  49,   0, 219, 206, 214, 210, 250,  38,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 247, 218, 212, 210, 215, 214,   0, 254, 243,\n",
              "        139, 255, 174, 251, 255, 205,   0, 215, 217, 214, 208, 220,  95,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,  45, 226, 214, 214, 215, 224, 205,   0,  42,  35,\n",
              "         60,  16,  17,  12,  13,  70,   0, 189, 216, 212, 206, 212, 156,\n",
              "          0,   0],\n",
              "       [  0,   0,   0, 164, 235, 214, 211, 220, 216, 201,  52,  71,  89,\n",
              "         94,  83,  78,  70,  76,  92,  87, 206, 207, 222, 213, 219, 208,\n",
              "          0,   0],\n",
              "       [  0,   0,   0, 106, 187, 223, 237, 248, 211, 198, 252, 250, 248,\n",
              "        245, 248, 252, 253, 250, 252, 239, 201, 212, 225, 215, 193, 113,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  17,  54, 159, 222, 193, 208, 192, 197,\n",
              "        200, 200, 200, 200, 201, 203, 195, 210, 165,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  47, 225, 192, 214, 203, 206,\n",
              "        204, 204, 205, 206, 204, 212, 197, 218, 107,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   1,   6,   0,  46, 212, 195, 212, 202, 206,\n",
              "        205, 204, 205, 206, 204, 212, 200, 218,  91,   0,   3,   1,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,  11, 197, 199, 205, 202, 205,\n",
              "        206, 204, 205, 207, 204, 205, 205, 218,  77,   0,   5,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   3,   0,   2, 191, 198, 201, 205, 206,\n",
              "        205, 205, 206, 209, 206, 199, 209, 219,  74,   0,   5,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   2,   0,   0, 188, 197, 200, 207, 207,\n",
              "        204, 207, 207, 210, 208, 198, 207, 221,  72,   0,   4,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   2,   0,   0, 215, 198, 203, 206, 208,\n",
              "        205, 207, 207, 210, 208, 200, 202, 222,  75,   0,   4,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 212, 198, 209, 206, 209,\n",
              "        206, 208, 207, 211, 206, 205, 198, 221,  80,   0,   3,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 204, 201, 205, 208, 207,\n",
              "        205, 211, 205, 210, 210, 209, 195, 221,  96,   0,   3,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 202, 201, 205, 209, 207,\n",
              "        205, 213, 206, 210, 209, 210, 194, 217, 105,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 204, 204, 205, 208, 207,\n",
              "        205, 215, 207, 210, 208, 211, 193, 213, 115,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 204, 207, 207, 208, 206,\n",
              "        206, 215, 210, 210, 207, 212, 195, 210, 118,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 198, 208, 208, 208, 204,\n",
              "        207, 212, 212, 210, 207, 211, 196, 207, 121,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 198, 210, 207, 208, 206,\n",
              "        209, 213, 212, 211, 207, 210, 197, 207, 124,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 172, 210, 203, 201, 199,\n",
              "        204, 207, 205, 204, 201, 205, 197, 206, 127,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 188, 221, 214, 234, 236,\n",
              "        238, 244, 244, 244, 240, 243, 214, 224, 162,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0, 139, 146, 130, 135, 135,\n",
              "        137, 125, 124, 125, 121, 119, 114, 130,  76,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-9db71b67-bc4a-4635-9570-4cebb25bf730 button').onclick = (e) => {\n",
              "        document.querySelector('#id-9db71b67-bc4a-4635-9570-4cebb25bf730').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-9db71b67-bc4a-4635-9570-4cebb25bf730 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e5qu2ncp5SR",
        "outputId": "8181e506-1560-4207-d83d-4ffedb99d7ef"
      },
      "source": [
        "Y_train"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfDsUsmCllY9"
      },
      "source": [
        "# specify the number of rows and columns you want to see\n",
        "num_row = 6\n",
        "num_col = 6\n",
        "\n",
        "# get a segment of the dataset\n",
        "num = num_row*num_col\n",
        "images = X_train[:num]\n",
        "labels = Y_train[:num]\n",
        "\n",
        "# plot images\n",
        "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "for i in range(num_row*num_col):\n",
        "    ax = axes[i//num_col, i%num_col]\n",
        "    ax.imshow(images[i], cmap='gray')\n",
        "    ax.set_title('Label: {}'.format(labels[i]))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H62x7DwVpc9B"
      },
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHUNnJz2pz_1"
      },
      "source": [
        "X_train[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKZx8P5CqCSI"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IG6Pw7VqDXA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "b980636c-2744-4ed7-d070-4e1b1b03f672"
      },
      "source": [
        "X = X_train.reshape(60000,784)\n",
        "y = Y_train\n",
        "clf = MLPClassifier(solver='adam', alpha=1e-5,\n",
        "                    hidden_layer_sizes=(12), random_state=1,max_iter = 200)\n",
        "\n",
        "clf.fit(X, y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(alpha=1e-05, hidden_layer_sizes=12, random_state=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=12, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=12, random_state=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipYZb9tEqa_B"
      },
      "source": [
        "y_pred = clf.predict(X_test.reshape(10000,784))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh_QWCjEu47P"
      },
      "source": [
        "def accuracy(confusion_matrix):\n",
        "   diagonal_sum = confusion_matrix.trace()\n",
        "   sum_of_all_elements = confusion_matrix.sum()\n",
        "   return diagonal_sum / sum_of_all_elements"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1h8dcj78yyl"
      },
      "source": [
        "class_names = [ \"T-shirt/top\" , \"Trouser\" , \"Pullover\" , \"Dress\" , \"Coat\" , \"Sandal\" , \"Shirt\" , \"Sneaker\" , \"Bag\" , \"Ankle boot\" ]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5VUy_Fv-HPv",
        "outputId": "88eb0c9a-cd3f-426f-d6e2-8eafb30c99e7"
      },
      "source": [
        "np.unique(Y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlEmaMLIuOai",
        "outputId": "82f87e58-09c3-4001-e200-33db4f9a5114"
      },
      "source": [
        "#Importing Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "#Comparing the predictions against the actual observations in y_val\n",
        "cm = confusion_matrix(Y_test,y_pred,labels=np.unique(Y_test))\n",
        "cm"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[832,   4,  14,  52,   3,   2,  85,   0,   8,   0],\n",
              "       [  2, 955,   5,  29,   4,   0,   2,   0,   2,   1],\n",
              "       [ 24,   3, 776,  14, 116,   1,  59,   0,   6,   1],\n",
              "       [ 37,  17,  19, 868,  30,   0,  24,   0,   5,   0],\n",
              "       [  1,   1, 122,  42, 773,   2,  53,   0,   6,   0],\n",
              "       [  0,   0,   0,   1,   0, 939,   0,  31,   4,  25],\n",
              "       [144,   1, 117,  52,  80,   0, 595,   1,  10,   0],\n",
              "       [  0,   0,   0,   0,   0,  23,   0, 952,   1,  24],\n",
              "       [ 15,   0,  11,   7,   5,   9,  13,   6, 933,   1],\n",
              "       [  0,   1,   0,   0,   0,  14,   1,  53,   0, 931]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz_pVO8y8a-M",
        "outputId": "1554497f-82bf-475f-ccf5-20c18c29a272"
      },
      "source": [
        "#Printing the accuracy\n",
        "print(\"Accuracy of MLPClassifier : \", accuracy(cm))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of MLPClassifier :  0.8554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "efYLJNbX-Usg",
        "outputId": "19bfee1c-7176-41b4-fc98-e54860855e42"
      },
      "source": [
        "classification_report(Y_test,y_pred,labels=np.unique(Y_test),target_names=class_names)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n T-shirt/top       0.73      0.80      0.76      1000\\n     Trouser       0.98      0.93      0.95      1000\\n    Pullover       0.69      0.69      0.69      1000\\n       Dress       0.77      0.87      0.81      1000\\n        Coat       0.71      0.73      0.72      1000\\n      Sandal       0.94      0.90      0.92      1000\\n       Shirt       0.59      0.45      0.51      1000\\n     Sneaker       0.89      0.94      0.92      1000\\n         Bag       0.92      0.94      0.93      1000\\n  Ankle boot       0.93      0.92      0.93      1000\\n\\n    accuracy                           0.82     10000\\n   macro avg       0.81      0.82      0.81     10000\\nweighted avg       0.81      0.82      0.81     10000\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def unitStep(v):\n",
        "    if v >= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def perceptronModel(x, w, b):\n",
        "    v = np.dot(w, x) + b\n",
        "    y = unitStep(v)\n",
        "    return y\n",
        "\n",
        "def AND(x):\n",
        "    w = np.array([1, 1])\n",
        "    b = -1.25\n",
        "    return perceptronModel(x, w, b)\n",
        "\n",
        "test1 = np.array([0, 0])\n",
        "test2 = np.array([0, 1])\n",
        "test3 = np.array([1, 0])\n",
        "test4 = np.array([1, 1])\n",
        "\n",
        "#\n",
        "\n",
        "\n",
        "print(\"AND[{}, {}] = {}\".format(0, 0, AND(test1)))\n",
        "print(\"AND[{}, {}] = {}\".format(0, 1, AND(test2)))\n",
        "print(\"AND[{}, {}] = {}\".format(1, 0, AND(test3)))\n",
        "print(\"AND[{}, {}] = {}\".format(1, 1, AND(test4)))\n",
        "\n",
        "\n",
        "\n",
        "def OR(x):\n",
        "    w = np.array([1, 1])\n",
        "    b = -0.9\n",
        "    return perceptronModel(x, w, b)\n",
        "\n",
        "\n",
        "print(\"OR[{}, {}] = {}\".format(0, 0, OR(test1)))\n",
        "print(\"OR[{}, {}] = {}\".format(0, 1, OR(test2)))\n",
        "print(\"OR[{}, {}] = {}\".format(1, 0, OR(test3)))\n",
        "print(\"OR[{}, {}] = {}\".format(1, 1, OR(test4)))\n",
        ""
      ],
      "metadata": {
        "id": "MWQZ-NUDklDT",
        "outputId": "e153045c-f8d6-4b2e-9e6e-7a410036fbb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND[0, 0] = 0\n",
            "AND[0, 1] = 0\n",
            "AND[1, 0] = 0\n",
            "AND[1, 1] = 1\n",
            "OR[0, 0] = 0\n",
            "OR[0, 1] = 1\n",
            "OR[1, 0] = 1\n",
            "OR[1, 1] = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mQjdRS71mv5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}